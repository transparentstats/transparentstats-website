---
title: "Statements for the 2021 VIS Committee Elections"
date: "2016-01-01"
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>A new member is being elected to the VIS Steering Committee (VSC) and the VIS Executive Committee (VEC), which provide scientific and organizational oversight of the IEEE VIS conference and reviewing process.</p>
<p>Following <a href="https://improvingpsych.org/mission/election-statements/">the example set by Society for the Improvement of Psychological Science</a>, members of the Transparent Statistics in HCI asked 2021 VSC and VEC candidates to publicly answer a question about research transparency and open practices: </p>
<blockquote>
<p><strong>If elected to the IEEE VIS [Committee], what (if any) policies would you promote to improve research in visualization, and how would you support open science practices and research transparency at IEEE VIS and in the field of visualization more broadly?</strong></p>
</blockquote>
<p>Because different areas within visualization vary considerably in existing norms and practices, and because the specific issues that are most salient may vary by sub-discipline, the question is very broad and open-ended. The email was signed by Steve Haroz, Fanny Chevalier, Lewis Chuang, Pierre Dragicevic, Shion Guha, and Matthew Kay.</p>
<p>Statements will be posted as they are received.</p>
<div id="vis-steering-committee" class="section level1">
<h1>VIS Steering Committee</h1>
<div id="chris-johnson" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vsc-candidates#chris-johnson">Chris Johnson</a></h3>
<p><em>Statement not yet received (request sent Sept. 13)</em></p>
</div>
<div id="kwan-liu-ma" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vsc-candidates#kwan-li-uma">Kwan-Liu Ma</a></h3>
<p>Even though VIS has created a set of well thought through guidelines for both authors and reviewers, we should not stop improving the paper review and selection process since this process is so crucial to the advancement of the field. I found the overemphasis of thorough evaluation and user studies for TVCG track papers often leads to acceptance of papers making only incremental contributions while rejecting papers presenting novel ideas. I like how other scientific disciplines recognize conference presentations focusing on original ideas and consider archiving subsequently. I would like to further promote the short papers or bring back a highly recognized conference track program. When asked to serve on this year’s VIS short papers committee, I was glad to find the emphasis of new and novel contributions rather than treating short papers as second class. So it’s a good start but not enough. I will also propose to re-examine the current VIS paper reviewing process for further improving the quality of the reviews and selections.</p>
<p>I am fully behind open science practices and research transparency. However, we need to be careful and reasonable in setting the expectation and educating both the researchers and reviewers about open science and reproducibility. All these require a community effort, and VIS/VGTC should lead and sponsor this effort. Therefore, I would support organizing and offering regular VIS conference workshops/tutorials as well as the development of online instruction materials on research transparency. Compared to 10 years ago, we have more basis and resources to teach visualization, but what is considered comprehensive education for visualization researchers? As a field, we should collectively develop a curriculum that includes transparent research in VIS.</p>
</div>
<div id="bernhard-preim" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vsc-candidates#bernhard-preim">Bernhard Preim</a></h3>
<p>I consider open science, e.g., open source software and open data, as essential primarily to foster reproducibility. The fact that many scientific results cannot be reproduced, is a severe problem for science in general. Thus, I consider the Graphics Replicability Stamp Initiative as an essential step in this direction and would support further initiatives to strengthen transparency. However, I am also aware of differences in the subcommunities. While open source software and public databases play an essential role in BioVis and BioInformatics, in medical applications, it is still rare that data can be made publicly available. Without example datasets, even an open source software is of limitied value. Thus, I would not favor that open source software is mandatory for publications at Vis.</p>
</div>
<div id="anna-vilanova" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vsc-candidates#anna-vilanova">Anna Vilanova</a></h3>
<p><em>Statement not yet received (request sent Sept. 13)</em></p>
</div>
</div>
<div id="vis-executive-committee" class="section level1">
<h1>VIS Executive Committee</h1>
<div id="rita-borgo" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vec-candidates#rita-borgo">Rita Borgo</a></h3>
<p><em>Statement not yet received (request sent Sept. 17)</em></p>
</div>
<div id="stefan-bruckner" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vec-candidates#stefan-bruckner">Stefan Bruckner</a></h3>
<p>As I also wrote in my candidate statement (see <a href="http://ieeevis.org/year/2021/info/vec-candidates#stefan-bruckner" class="uri">http://ieeevis.org/year/2021/info/vec-candidates#stefan-bruckner</a>), if elected, I plan to actively support and promote initiatives dedicated to furthering open science practices and transparency.</p>
<p>There are several measures that I think would be worthwhile investigating. In particular, I believe it is important to create stronger incentive structures for making source code, data, and other artefacts available to the community. Initiatives such as the GRSI are gaining some traction also in the visualization community, but at the level of VIS there is, at present, no explicit tie-in with such efforts (unlike for direct TVCG submissions, for instance). Furthermore, I think a dedicated award for papers that go significantly beyond what is required in this respect would be a good starting point to signal that such efforts are recognized and worthwhile. This also goes hand-in-hand with a better integration of questions of transparency into the review process.</p>
<p>However, I believe that it is also important to recognize that the partial reluctance towards implementing such policies is not due to malicious intent. For instance, as someone who has worked with collaborators in industry for many years, I know that it can be very difficult to get stakeholders on board with what some may see as potentially detrimental to their interests. We need to be conscious of such issues and make sure that all opinions on the topic are openly discussed and considered. As can also be seen from the measures proposed above, I believe a progressive effort towards encouraging, incentivising, and providing visibility to works that follow the best practices is the way to go here (as opposed to strong enforcement). I believe that our community has shown – for instance in the excellent work of the reVISe committee – that it is capable of driving forward dedicated efforts to renew itself substantially and I am confident that the changes in the governance of VIS will be a great contributor to make similar advances in open practices.</p>
</div>
<div id="michael-correll" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vec-candidates#michael-correll">Michael Correll</a></h3>
<p>As a researcher in communicating uncertainty and statistical concepts to non-statistical audiences, as a participant in organizations dedicated to statistical openness (such as the Transparent Statistics in HCI group), and as a frequent commenter on the epistemological and communicative conundrums at the core of visualization research, establishing thoughtful and rigorous norms around how we conduct and report on our research is a core concern of mine. Hopefully the centrality of this concern is reflected in both my work and my VEC candidate statement. I will use my response here to highlight some potential areas where I think we could (or should) change as a conference.</p>
<p>I will preface any statements about policy by saying that one of the things that draws me to the visualization community is that we come from many backgrounds and have a wide and varied view of what it means to do “good” visualization research. Any schemes to “improve” research in visualization must be undertaken from this assumption of plurality: standards that work for an author presenting a graphical perception study would look quite different than standards for an author presenting a novel rendering algorithm, or one presenting a close reading of a visualization on historical or aesthetic grounds.</p>
<p>With that said, I believe that we can look to other fields and conferences for examples of policies that work to encourage openness, rigor, and reliability. Both the disruptions to the usual way of presenting work caused by the pandemic and by new legislation such as the EU’s Plan S are long-overdue crises that will require us to rethink the publication model in any event, so why not build one that is more conducive to better practices from the outset? “Encourage” is the key word for me here; I think we will have more success providing positive reinforcement for high-quality research as opposed to introducing new, stricter, and potentially unfamiliar rules or punishments. Other conferences are taking big bets or performing big experiments around how work is submitted (rolling deadlines, revise-and-resubmit options, and rebuttals) as well as on the contents and structure of that submitted work (requiring statements of broader impacts, positionally, or data accessibility). As we learn more about the results of those experiments, we should borrow, adapt, or outright copy the things that work.</p>
<p>One particular form of encouragement I would like to see is a more expansive view of conference contributions other than “10 pages of static content due on a specific date and published in isolation in a special edition of a journal.” Preregistrations, registered reports, and replications are artifacts that can shore up the rigor of empirical work. Yet, these artifacts are currently rare or, at best, co-exist uneasily with the standard IEEE VIS reviewing and publication model. We need to make room for this sort of work at VIS. Providing official and explicit guidance, recognition, and promotion for these sorts of “non-standard” research artifacts would go a long way towards moving these practices from the periphery to the core of empirical work at VIS.</p>
</div>
<div id="helwig-hauser" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vec-candidates#helwig-hauser">Helwig Hauser</a></h3>
<p><em>Statement not yet received (request sent Sept. 17)</em></p>
</div>
<div id="filip-sadlo" class="section level3">
<h3><a href="http://ieeevis.org/year/2021/info/vec-candidates#filip-sadlo">Filip Sadlo</a></h3>
<p><em>Statement not yet received (request sent Sept. 17)</em></p>
</div>
</div>
